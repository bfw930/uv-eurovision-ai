{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' imports '''\n",
    "\n",
    "# set auto reload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# general imports\n",
    "import os, shutil\n",
    "\n",
    "# numpy for array handling\n",
    "import numpy as np\n",
    "\n",
    "# import pytorch core libs\n",
    "import torch\n",
    "\n",
    "# write audio to file\n",
    "from librosa.output import write_wav\n",
    "\n",
    "\n",
    "''' sample-rnn components '''\n",
    "# add sample-rnn libs directory to path\n",
    "import sys\n",
    "sys.path.append('../libs/samplernn/')\n",
    "\n",
    "# import core sample-rnn model (inc. frame-lvl rnn and sample-lvl mlp)\n",
    "from model import SampleRNN\n",
    "from model import Predictor\n",
    "from model import Generator\n",
    "\n",
    "# wrapper for optimiser\n",
    "from optim import gradient_clipping\n",
    "\n",
    "# training criterion\n",
    "from nn import sequence_nll_loss_bits\n",
    "\n",
    "# import audio dataset management\n",
    "from dataset import FolderDataset\n",
    "from dataset import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../libs/samplernn/nn.py:62: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
      "  init(chunk)\n"
     ]
    }
   ],
   "source": [
    "''' initialise models components '''\n",
    "\n",
    "# model parameters\n",
    "_frame_sizes = (16, 4)\n",
    "_n_rnn = 1\n",
    "_dim = 1024\n",
    "_learn_h0 = True\n",
    "_q_levels = 256 # 8 bit depth\n",
    "_weight_norm = True\n",
    "\n",
    "# initialise sample-rnn model\n",
    "model = SampleRNN(\n",
    "    frame_sizes = _frame_sizes,\n",
    "    n_rnn = _n_rnn,\n",
    "    dim = _dim,\n",
    "    learn_h0 = _learn_h0,\n",
    "    q_levels = _q_levels,\n",
    "    weight_norm = _weight_norm\n",
    ")\n",
    "\n",
    "# intitialise predictor model\n",
    "predictor = Predictor(model)\n",
    "\n",
    "generator = Generator(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' push to device '''\n",
    "\n",
    "# get computing device\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# push models to device\n",
    "model = model.to(device)\n",
    "predictor = predictor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' init optimiser '''\n",
    "\n",
    "# get model parameters\n",
    "params = predictor.parameters()\n",
    "\n",
    "# initialise optimiser\n",
    "optimizer = gradient_clipping( torch.optim.Adam(params) )\n",
    "#optimizer = torch.optim.Adam(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' initialise dataset and dataloader '''\n",
    "\n",
    "# define dataset\n",
    "_datasets_path = '../data/'\n",
    "_dataset = 'piano-small'\n",
    "_path = os.path.join(_datasets_path, _dataset)\n",
    "\n",
    "\n",
    "# get number frame samples of final frame-level rnn in model\n",
    "_overlap_len = model.lookback\n",
    "\n",
    "_seq_len = 1024\n",
    "_batch_size = 64\n",
    "\n",
    "_train_frac = 0.9\n",
    "\n",
    "# initialise dataset\n",
    "train_dataset = FolderDataset(\n",
    "    _path,\n",
    "    _overlap_len,\n",
    "    _q_levels,\n",
    "    0,\n",
    "    _train_frac,\n",
    ")\n",
    "\n",
    "# intitialise dataloader\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = _batch_size,\n",
    "    seq_len = _seq_len,\n",
    "    overlap_len = _overlap_len,\n",
    "    \n",
    "    #shuffle = True,\n",
    "    #drop_last = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../libs/samplernn/model.py:181: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x.view(-1, self.q_levels)) \\\n"
     ]
    }
   ],
   "source": [
    "''' training loop '''\n",
    "\n",
    "# set training epochs\n",
    "epochs = 1\n",
    "\n",
    "# perform training model over epochs, iterate over range epoch limit\n",
    "for _epoch in range(epochs):\n",
    "\n",
    "    #print('epoch: ', _epoch)\n",
    "    \n",
    "    ## model training, given dataset compute loss and update model parameters\n",
    "    \n",
    "    # set model to training mode (gradients stored)\n",
    "    predictor.train()\n",
    "    \n",
    "    # iterate over dataset\n",
    "    for (_iteration, data) in enumerate(train_data_loader):\n",
    "\n",
    "        #print('iteration: ', _iteration)\n",
    "        \n",
    "        # zero gradients and step optimiser\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # unpack dataset\n",
    "        batch_inputs = data[0].to(device)\n",
    "        batch_target = data[-1].to(device)\n",
    "        \n",
    "        # reevaluate the function multiple times; clear the gradients, compute and return loss\n",
    "        def closure():\n",
    "\n",
    "            # pass inputs through model, return output\n",
    "            #batch_output = predictor(batch_inputs, reset = data[1])\n",
    "            batch_output = predictor(batch_inputs, reset = False)\n",
    "\n",
    "            # calculate loss for inputs to outputs\n",
    "            loss = sequence_nll_loss_bits(batch_output, batch_target)\n",
    "\n",
    "            #print(loss)\n",
    "\n",
    "            # calculate gradients and return loss\n",
    "            loss.backward()\n",
    "\n",
    "            return loss\n",
    "\n",
    "        # step optimiser with closure\n",
    "        optimizer.step(closure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../libs/samplernn/model.py:269: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  prev_samples = torch.autograd.Variable(\n",
      "../libs/samplernn/model.py:292: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  prev_samples = torch.autograd.Variable(\n"
     ]
    }
   ],
   "source": [
    "''' perform sample generation '''\n",
    "\n",
    "# define dataset\n",
    "_output_path = '../data/'\n",
    "\n",
    "_sample_rate = 16000\n",
    "_n_samples = 1\n",
    "_sample_length = int(_sample_rate * 3)\n",
    "\n",
    "# intiialise generator\n",
    "\n",
    "samples = generator(_n_samples, _sample_length).cpu().float().numpy()\n",
    "\n",
    "for i in range(_n_samples):\n",
    "    write_wav(\n",
    "        os.path.join(_output_path, 'test-out.wav'),\n",
    "        samples[i, :], sr = _sample_rate, norm = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' save checkpoint '''\n",
    "\n",
    "torch.save(predictor.state_dict(), '../data/chkpt-sml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' load checkpoint '''\n",
    "\n",
    "#_state_dict = torch.load('../data/chkpt')\n",
    "_state_dict = torch.load('../data/chkpt-sml')\n",
    "\n",
    "predictor.load_state_dict(_state_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eurovision-ai",
   "language": "python",
   "name": "eurovision-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
