{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' imports '''\n",
    "\n",
    "# set auto reload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# general imports\n",
    "import os, shutil\n",
    "\n",
    "# numpy for array handling\n",
    "import numpy as np\n",
    "\n",
    "# import pytorch core libs\n",
    "import torch\n",
    "\n",
    "# write audio to file\n",
    "from librosa.output import write_wav\n",
    "\n",
    "\n",
    "''' sample-rnn components '''\n",
    "# add sample-rnn libs directory to path\n",
    "import sys\n",
    "\n",
    "sys.path.append('../libs/samplernn/')\n",
    "\n",
    "# import core sample-rnn model (inc. frame-lvl rnn and sample-lvl mlp)\n",
    "from model import SampleRNN\n",
    "from model import Predictor\n",
    "from model import Generator\n",
    "\n",
    "# wrapper for optimiser\n",
    "from optim import gradient_clipping\n",
    "\n",
    "# training criterion\n",
    "from nn import sequence_nll_loss_bits\n",
    "\n",
    "# import audio dataset management\n",
    "from dataset import FolderDataset\n",
    "from dataset import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../libs/samplernn/nn.py:62: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
      "  init(chunk)\n"
     ]
    }
   ],
   "source": [
    "''' initialise models components '''\n",
    "# \"new\" model parameters\n",
    "#_frame_sizes = (4, 4, 8, 8)\n",
    "#_n_rnn = 2\n",
    "#_dim = 1024\n",
    "#_learn_h0 = False\n",
    "#_q_levels = 256 # 8 bit depth\n",
    "#_weight_norm = Tru\n",
    "\n",
    "# model parameters\n",
    "_frame_sizes = (4, 4, 4)\n",
    "_n_rnn = 1\n",
    "_dim = 1024\n",
    "_learn_h0 = True\n",
    "_q_levels = 256 # 8 bit depth\n",
    "_weight_norm = True\n",
    "\n",
    "# initialise sample-rnn model\n",
    "model = SampleRNN(\n",
    "    frame_sizes = _frame_sizes,\n",
    "    n_rnn = _n_rnn,\n",
    "    dim = _dim,\n",
    "    learn_h0 = _learn_h0,\n",
    "    q_levels = _q_levels,\n",
    "    weight_norm = _weight_norm\n",
    ")\n",
    "\n",
    "# intitialise predictor model\n",
    "predictor = Predictor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' push to device '''\n",
    "\n",
    "# get computing device\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # step opt\n",
    "# push models to device\n",
    "model = model.to(device)\n",
    "predictor = predictor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' init optimiser '''\n",
    "\n",
    "# get model parameters\n",
    "params = predictor.parameters()\n",
    "\n",
    "\n",
    "# initialise optimiser\n",
    "optimizer = gradient_clipping( torch.optim.Adam(params, lr = 1e-4))\n",
    "#optimizer = torch.optim.Adam(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # step opt''' initialise dataset and dataloader '''\n",
    "\n",
    "# define dataset\n",
    "_datasets_path = '../data/'\n",
    "_dataset = 'vox'\n",
    "_path = os.path.join(_datasets_path, _dataset)\n",
    "\n",
    "\n",
    "# get number frame samples of final frame-level rnn in model\n",
    "_overlap_len = model.lookback\n",
    "\n",
    "_seq_len = 2048\n",
    "_batch_size = 64\n",
    "\n",
    "_train_frac = 1\n",
    "\n",
    "# initialise dataset\n",
    "train_dataset = FolderDataset(\n",
    "    _path,\n",
    "    _overlap_len,\n",
    "    _q_levels,\n",
    "    0,\n",
    "    _train_frac,\n",
    "\n",
    ")\n",
    "\n",
    "# intitialise dataloader\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = _batch_size,\n",
    "    seq_len = _seq_len,\n",
    "    overlap_len = _overlap_len,\n",
    "    \n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    drop_last = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "Caught IsADirectoryError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/librosa/core/audio.py\", line 129, in load\n    with sf.SoundFile(path) as sf_desc:\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/soundfile.py\", line 629, in __init__\n    self._file = self._open(file, mode_int, closefd)\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/soundfile.py\", line 1183, in _open\n    _error_check(_snd.sf_error(file_ptr),\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/soundfile.py\", line 1357, in _error_check\n    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\nRuntimeError: Error opening '../data/vox/output': File contains data in an unknown format.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"../libs/samplernn/dataset.py\", line 34, in __getitem__\n    (seq, _) = load(self.file_names[index], sr = None, mono = True)\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/librosa/core/audio.py\", line 162, in load\n    y, sr_native = __audioread_load(path, offset, duration, dtype)\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/librosa/core/audio.py\", line 186, in __audioread_load\n    with audioread.audio_open(path) as input_file:\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/audioread/__init__.py\", line 111, in audio_open\n    return BackendClass(path)\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/audioread/rawread.py\", line 62, in __init__\n    self._fh = open(filename, 'rb')\nIsADirectoryError: [Errno 21] Is a directory: '../data/vox/output'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-74b7b44094d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# iterate over dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#print('iteration: ', _iteration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/eurovision-ai/libs/samplernn/dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m: Caught IsADirectoryError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/librosa/core/audio.py\", line 129, in load\n    with sf.SoundFile(path) as sf_desc:\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/soundfile.py\", line 629, in __init__\n    self._file = self._open(file, mode_int, closefd)\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/soundfile.py\", line 1183, in _open\n    _error_check(_snd.sf_error(file_ptr),\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/soundfile.py\", line 1357, in _error_check\n    raise RuntimeError(prefix + _ffi.string(err_str).decode('utf-8', 'replace'))\nRuntimeError: Error opening '../data/vox/output': File contains data in an unknown format.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"../libs/samplernn/dataset.py\", line 34, in __getitem__\n    (seq, _) = load(self.file_names[index], sr = None, mono = True)\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/librosa/core/audio.py\", line 162, in load\n    y, sr_native = __audioread_load(path, offset, duration, dtype)\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/librosa/core/audio.py\", line 186, in __audioread_load\n    with audioread.audio_open(path) as input_file:\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/audioread/__init__.py\", line 111, in audio_open\n    return BackendClass(path)\n  File \"/home/brendan/.local/share/virtualenvs/eurovision-ai-vARDGvzQ/lib/python3.8/site-packages/audioread/rawread.py\", line 62, in __init__\n    self._fh = open(filename, 'rb')\nIsADirectoryError: [Errno 21] Is a directory: '../data/vox/output'\n"
     ]
    }
   ],
   "source": [
    "''' training loop '''\n",
    "\n",
    "# set training epochs\n",
    "epochs = 5\n",
    "\n",
    "# perform training model over epochs, iterate over range epoch limit\n",
    "for _epoch in range(epochs):\n",
    "\n",
    "    #print('epoch: ', _epoch)\n",
    "    \n",
    "    ## model training, given dataset compute loss and update model parameters\n",
    "    \n",
    "    # set model to training mode (gradients stored)\n",
    "    predictor.train()\n",
    "    \n",
    "    # iterate over dataset\n",
    "    for (_iteration, data) in enumerate(train_data_loader):\n",
    "\n",
    "        #print('iteration: ', _iteration)\n",
    "        \n",
    "        # step opt\n",
    "        # zero gradients and step optimiser\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # unpack dataset\n",
    "        batch_inputs = data[0].to(device)\n",
    "        batch_target = data[-1].to(device)\n",
    "        \n",
    "        # reevaluate the function multiple times; clear the gradients, compute and return loss\n",
    "        def closure():\n",
    "\n",
    "            # pass inputs through model, return output\n",
    "            batch_output = predictor(batch_inputs, reset = data[1])\n",
    "            #batch_output = predictor(batch_inputs, reset = False)\n",
    "\n",
    "            # calculate loss for inputs to outputs\n",
    "            loss = sequence_nll_loss_bits(batch_output, batch_target)\n",
    "\n",
    "            #print(loss.item())\n",
    "\n",
    "            # calculate gradients and return loss`\n",
    "            loss.backward()\n",
    "\n",
    "            return loss\n",
    "\n",
    "        try:\n",
    "            # step optimiser with closure\n",
    "            optimizer.step(closure)\n",
    "            \n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' perform sample generation '''\n",
    "\n",
    "# define datasethttps://www.youtube.com/watch?v=t8WEIKBUSAw\n",
    "_output_path = '../data/vox/output-2'\n",
    "\n",
    "#_sample_rate = 44000\n",
    "_sample_rate = 16000\n",
    "_n_samples = 1\n",
    "_sample_length = int(_sample_rate * 10)\n",
    "\n",
    "# intiialise generator\n",
    "\n",
    "samples = generator(_n_samples, _sample_length).cpu().float().numpy()\n",
    "\n",
    "for i in range(_n_samples):\n",
    "    write_wav(\n",
    "        os.path.join(_output_path, 'vox_euro_04_{}.wav'.format(i)),\n",
    "        samples[i, :], sr = _sample_rate, norm = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' save checkpoint '''\n",
    "\n",
    "torch.save(model.state_dict(), '../data/vox/output-2/chkpt-03')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' load checkpoint '''\n",
    "\n",
    "#_state_dict = torch.load('../data/chkpt')\n",
    "_state_dict = torch.load('../data/vox/output/chkpt-new-05')\n",
    "\n",
    "model.load_state_dict(_state_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eurovision-ai",
   "language": "python",
   "name": "eurovision-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
