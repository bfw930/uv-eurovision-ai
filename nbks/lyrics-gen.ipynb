{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' imports '''\n",
    "\n",
    "import os, pickle, random, re, shutil\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# model\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "\n",
    "# GTP-2 transformer model\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    GPT2Config,\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' text dataset '''\n",
    "\n",
    "class LineByLineTextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer, file_path: str, block_size = 512):\n",
    "\n",
    "        # no feature cache\n",
    "        with open(file_path, encoding = 'utf-8') as f:\n",
    "\n",
    "            lines = [line for line in f.read().splitlines()\n",
    "                     if (len(line) > 0 and not line.isspace())]\n",
    "\n",
    "        self.examples = tokenizer.batch_encode_plus(\n",
    "            lines, add_special_tokens = True, max_length = block_size)['input_ids']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return torch.tensor(self.examples[i], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' config parameters '''\n",
    "\n",
    "# Optional input sequence length after tokenization.\n",
    "# The training dataset will be truncated in block of this size for training\n",
    "# Default to the model max input length for single sentence inputs (take into account special tokens)\n",
    "block_size: int = -1\n",
    "\n",
    "# Number of updates steps to accumulate before performing a backward/update pass\n",
    "gradient_accumulation_steps: int = 1\n",
    "\n",
    "# Max gradient norm\n",
    "max_grad_norm: float = 1.\n",
    "\n",
    "# If > 0: set total number of training steps to perform. Override num_train_epochs\n",
    "max_steps: int = -1\n",
    "\n",
    "# Linear warmup over warmup_steps\n",
    "warmup_steps: int = 0\n",
    "\n",
    "\n",
    "''' init train env '''\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = 1\n",
    "\n",
    "\n",
    "# Set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load pretrained model and tokenizer '''\n",
    "\n",
    "# load pretrained model and tokenizer\n",
    "config_class, model_class, tokenizer_class = GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init pretrained tokeniser\n",
    "tokenizer = tokenizer_class.from_pretrained('gpt2', cache_dir = None)\n",
    "\n",
    "\n",
    "# Our input block size will be the max possible for the model\n",
    "if block_size <= 0:\n",
    "    block_size = tokenizer.max_len\n",
    "else:\n",
    "    block_size = min(block_size, tokenizer.max_len)\n",
    "\n",
    "\n",
    "# init config\n",
    "config = config_class()\n",
    "\n",
    "# Training new model from scratch\n",
    "#model = model_class(config = config)\n",
    "\n",
    "model = model_class.from_pretrained('gpt2', config = config)\n",
    "\n",
    "# push model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' init dataset '''\n",
    "\n",
    "# get training dataset\n",
    "#file_path = '../data/lyrics/eurovision-lyrics-lines.txt'\n",
    "#file_path = '../data/lyrics/wikitext-2/wiki.train.tokens'\n",
    "#file_path = '../data/lyrics/eurovision-lyrics-en-lines'\n",
    "file_path = '../data/lyrics/eurovision-lyrics-lines-full'\n",
    "#file_path = '../data/lyrics/eurovision-lyrics-en-lines-lrg'\n",
    "#file_path = '../data/lyrics/lyricsnoheaders.txt'\n",
    "\n",
    "# init dataset\n",
    "train_dataset = LineByLineTextDataset(\n",
    "    tokenizer, file_path = file_path, block_size = block_size)\n",
    "#train_dataset = TextDataset(tokenizer, args, file_path=file_path, block_size = block_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" init dataloader, optimiser \"\"\"\n",
    "\n",
    "# set batch size\n",
    "train_batch_size = 4\n",
    "\n",
    "# define data aggregation per batch\n",
    "def collate(examples: List[torch.Tensor]):\n",
    "\n",
    "    if tokenizer._pad_token is None:\n",
    "\n",
    "        return pad_sequence(examples, batch_first = True)\n",
    "\n",
    "    return pad_sequence(examples, batch_first = True, padding_value = tokenizer.pad_token_id)\n",
    "\n",
    "# init random sampler on dataset\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "\n",
    "# init dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, sampler = train_sampler, batch_size = train_batch_size, collate_fn = collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' init optimiser, learning rate scheduler '''\n",
    "\n",
    "# The initial learning rate for Adam\n",
    "learning_rate: float = 5e-5\n",
    "\n",
    "# Weight decay if we apply some\n",
    "weight_decay: float = 0.\n",
    "\n",
    "# Epsilon for Adam optimizer\n",
    "adam_epsilon: float = 1e-8\n",
    "\n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": weight_decay,\n",
    "    },\n",
    "    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]\n",
    "\n",
    "# init optimiser on model parameters\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr = learning_rate, eps = adam_epsilon)\n",
    "\n",
    "\n",
    "\n",
    "# set training epochs\n",
    "num_train_epochs = 6\n",
    "\n",
    "# get total steps\n",
    "if max_steps > 0:\n",
    "    t_total = max_steps\n",
    "    num_train_epochs = max_steps // (len(train_dataloader) // gradient_accumulation_steps) + 1\n",
    "else:\n",
    "    t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\n",
    "    \n",
    "\n",
    "# init learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps = warmup_steps, num_training_steps = t_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 3.555682910680771\n",
      "200 3.4455769008398054\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-381766ecfc80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# push data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "''' perform training '''\n",
    "\n",
    "global_step = 0\n",
    "epochs_trained = 0\n",
    "steps_trained_in_current_epoch = 0\n",
    "\n",
    "tr_loss, logging_loss = 0.0, 0.0\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# zero gradients\n",
    "model.zero_grad()\n",
    "\n",
    "# iterate epochs\n",
    "for epoch in range(num_train_epochs):\n",
    "\n",
    "    # get data batch from dataloader\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Skip past any already trained steps if resuming training\n",
    "        if steps_trained_in_current_epoch > 0:\n",
    "            steps_trained_in_current_epoch -= 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        # unpack batch data\n",
    "        inputs, labels = (batch, batch)\n",
    "\n",
    "        # push data to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        # set model to train\n",
    "        model.train()\n",
    "\n",
    "        try:\n",
    "        \n",
    "            # perform forward pass through model\n",
    "            outputs = model(inputs, labels=labels)\n",
    "\n",
    "            # obtain loss; model outputs are always tuple in transformers\n",
    "            loss = outputs[0]\n",
    "\n",
    "            # gradient accumulation\n",
    "            if gradient_accumulation_steps > 1:\n",
    "                loss = loss / gradient_accumulation_steps\n",
    "\n",
    "            # backprop loss\n",
    "            loss.backward()\n",
    "\n",
    "            # store loss\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "\n",
    "                # perform gradient normalisation\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "                # step optimiser\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update learning rate schedule\n",
    "                scheduler.step()\n",
    "\n",
    "\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "        except:\n",
    "            pass # handle occasional invalid line data, skip\n",
    "            \n",
    "        if global_step % 100 == 0:\n",
    "            print(global_step, tr_loss / global_step)\n",
    "\n",
    "        if max_steps > 0 and global_step > max_steps:\n",
    "            break\n",
    "    if max_steps > 0 and global_step > max_steps:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/lyrics/model-lyrics-best-2/vocab.json',\n",
       " '../data/lyrics/model-lyrics-best-2/merges.txt',\n",
       " '../data/lyrics/model-lyrics-best-2/special_tokens_map.json',\n",
       " '../data/lyrics/model-lyrics-best-2/added_tokens.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' saving '''\n",
    "\n",
    "model.save_pretrained('../data/lyrics/model-lyrics-best-2')\n",
    "tokenizer.save_pretrained('../data/lyrics/model-lyrics-best-2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' loading '''\n",
    "\n",
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model = model_class.from_pretrained('../data/lyrics/model-lyrics-best-2')\n",
    "tokenizer = tokenizer_class.from_pretrained('../data/lyrics/model-lyrics-best-2')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love, love, love, love\n",
      "love is why we fight, love is why we fight\n",
      "love goes away\n",
      "love is all around you\n",
      "love is even deeper\n",
      "love of mine, you know\n",
      "love, you won’t regret it\n",
      "love, my love\n",
      "love is the love we got, love is the love we got\n",
      "love is just like a blessing in disguise\n",
      "love you like I do\n",
      "love I’m moving on\n",
      "love is turning back the rhythm\n",
      "love’s a miracle\n",
      "love’s gonna rock you up\n"
     ]
    }
   ],
   "source": [
    "''' perform text generation '''\n",
    "\n",
    "# input prompt to model\n",
    "prompt: str = 'love'\n",
    "\n",
    "# max length desired output\n",
    "length: int = 50\n",
    "#length: int = 40\n",
    "\n",
    "# Token at which text generation is stopped\n",
    "#stop_token: str = None\n",
    "stop_token: str = '!'\n",
    "    \n",
    "    \n",
    "# temperature of 1.0 has no effect, lower tend toward greedy sampling\n",
    "temperature:float = 1.\n",
    "\n",
    "# primarily useful for CTRL model; in that case, use 1.2\n",
    "repetition_penalty: float = 1.\n",
    "\n",
    "k: int = 0\n",
    "p: float = 0.9\n",
    "\n",
    "\n",
    "# The number of samples to generate\n",
    "num_return_sequences: int = 16\n",
    "\n",
    "    \n",
    "for i in range(1):\n",
    "\n",
    "    # Initialize the model and tokenizer\n",
    "    #model_class, tokenizer_class = (GPT2LMHeadModel, GPT2Tokenizer)\n",
    "\n",
    "    #tokenizer = tokenizer_class.from_pretrained('gpt2')\n",
    "    #model = model_class.from_pretrained('../data/lyrics/model-en-lyrics-02')\n",
    "    #model.to(device)\n",
    "\n",
    "\n",
    "    MAX_LENGTH = int(10000)  # Hardcoded max length to avoid infinite loop\n",
    "\n",
    "    def adjust_length_to_model(length, max_sequence_length):\n",
    "        if length < 0 and max_sequence_length > 0:\n",
    "            length = max_sequence_length\n",
    "        elif 0 < max_sequence_length < length:\n",
    "            length = max_sequence_length  # No generation bigger than model size\n",
    "        elif length < 0:\n",
    "            length = MAX_LENGTH  # avoid infinite loop\n",
    "        return length\n",
    "\n",
    "    length = adjust_length_to_model(\n",
    "        length, max_sequence_length = model.config.max_position_embeddings)\n",
    "\n",
    "\n",
    "    # encode prompt text, push to device\n",
    "    prompt_text = prompt\n",
    "    encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens = False, return_tensors = \"pt\")\n",
    "    encoded_prompt = encoded_prompt.to(device)\n",
    "\n",
    "\n",
    "    # generate output sequence\n",
    "    output_sequences = model.generate(\n",
    "\n",
    "        input_ids = encoded_prompt,\n",
    "\n",
    "        max_length = length + len(encoded_prompt[0]),\n",
    "        temperature = temperature,\n",
    "        top_k = k,\n",
    "        top_p = p,\n",
    "        repetition_penalty = repetition_penalty,\n",
    "        do_sample = True,\n",
    "        num_return_sequences = num_return_sequences,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Remove the batch dimension when returning multiple sequences\n",
    "    if len(output_sequences.shape) > 2:\n",
    "        output_sequences.squeeze_()\n",
    "\n",
    "    generated_sequences = []\n",
    "\n",
    "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "\n",
    "        generated_sequence = generated_sequence.tolist()\n",
    "\n",
    "        # Decode text\n",
    "        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces = True)\n",
    "\n",
    "        # Remove all text after the stop token\n",
    "        text = text[: text.find(stop_token) if stop_token else None]\n",
    "\n",
    "        # Add the prompt at the beginning of the sequence.\n",
    "        # Remove the excess text that was used for pre-processing\n",
    "        total_sequence = (\n",
    "            prompt_text + text[len(tokenizer.decode(\n",
    "                encoded_prompt[0], clean_up_tokenization_spaces = True)) :] )\n",
    "\n",
    "        \n",
    "        if len(total_sequence.split(' ')) > 2:\n",
    "            generated_sequences.append(total_sequence)\n",
    "            print(total_sequence)\n",
    "        \n",
    "        #print(prompt)\n",
    "        #prompt = total_sequence[-5:]\n",
    "\n",
    "    #return generated_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ding a dong, ask if I want, if I want\n",
      "ding a dong for me, I'll be yours forever\n",
      "ding a dong, hold me till dawn, say you love me like a loving mother\n",
      "ding a dong when you say your love for life ends\n",
      "ding a dong with the beat and then it broke\n",
      "ding a dong, put your money where your mouth is\n",
      "ding a dong to wake you up\n",
      "ding a dong, ring a bell\n",
      "ding a dong to get your attention\n",
      "ding a dong when your lover is gone\n",
      "ding a dong and pick a flower\n",
      "ding a dong to slow the rhythm\n",
      "ding a dong, beat the drum and sing along\n",
      "ding a dong, make a sound\n",
      "ding a dong, a dong\n",
      "ding a dong for me\n",
      "ding a dong, if you wanna lose, just hold me tight\n",
      "ding a dong, I wanna sing it\n",
      "ding a dong to the girl that you played\n",
      "ding a dong, tell me what's happening\n",
      "ding a dong, just sing it like a hummingbird\n",
      "ding a dong with that bird that perches on his rug\n",
      "ding a dong, sweet song, thank you, darling\n",
      "ding a dong when I'm beating on a string\n",
      "ding a dong, make it stop and be gone\n",
      "ding a dong, please, come and say goodbye\n",
      "ding a dong to try and find my weakness\n",
      "ding a dong to dance\n",
      "ding a dong with your guitar, mmm…\n",
      "ding a dong when he plays a dong\n",
      "ding a dong, dance with my dolls, couleurs-toi?\n",
      "ding a dong when I'm gone\n",
      "ding a dong to raise your voice\n",
      "ding a dong, hold me tight, oh come on\n",
      "ding a dong, push it, baby\n",
      "ding a dong that says that you love me madly\n",
      "ding a dong with me, we'll be sorry\n",
      "ding a dong with the tag on it\n",
      "ding a dong with my song\n",
      "ding a dong, ring a dinga dinga dinga\n",
      "ding a dong for me\n",
      "ding a dong for a beat and everyone will sing\n",
      "ding a dong with me\n",
      "ding a dong to add joy, because you make me sad\n",
      "ding a dong, one, two, three\n",
      "ding a dong and sing it like a hummingbird\n",
      "ding a dong to catch my drift\n",
      "lulu la regia, to ei ei ei cengad tei-ei vaso e i tante paso-dei c\n",
      "lulu la botačka hayimu posti?\n",
      "lulu la villade på dig dig\n",
      "lulu laht skal je vorcht\n",
      "lulu la vista, lulu la vista\n",
      "lulu la tinjesz butzę zmajći, la stensz vázmaj\n",
      "lulu laikaade dhikva, faina nu minha tähti vekya\n",
      "lulu la ti t'espesa a tonixi\n",
      "lulu la luna bistà\n",
      "lulu la ine et lacrima um ausleib\n",
      "lulu la... la la la la la la... la la la la la la la la la... la la la la la la la...\n",
      "lulu la lève végie, la lève dit éponéx\n",
      "lulu la gente pluto sincero\n",
      "lulu la hora è un nuovo sovrana\n",
      "lulu laiki hach' ich kojel zo vorbei\n",
      "lulu la liene t'était, sais tout est brais, sont le plus belle\n",
      "lulu la peut-être les visages\n",
      "lulu la nuku, då luna luku\n",
      "lulu la lluvia, på hander les livres encore\n",
      "lulu la luna luna\n",
      "lulu la stia to shel lyom lume\n",
      "lulu la ti miei ja karelloloni\n",
      "lulu la joie, la joie de ta jouer dans un weekend du grandée\n",
      "lulu la luna to sad li minha sur tha nevente uma teria d'espressati e te perdrei pi\n",
      "lulu la pluie, la pluie\n",
      "lulu la lulu la...\n",
      "lulu la luna, hääs ka'n navila\n",
      "lulu la thatungina, lulululula\n",
      "lulu la ti ti da nebiš\n",
      "lulu la loi je douze points\n",
      "lulu la terra alleux, la terra alleux\n",
      "lulu la não jamais que teke haver joie\n",
      "lulu laž ta da toz još katin na svinaće gudem ba\n",
      "lulu la vie loin danser\n",
      "lulu la saiai tu atå på og suive thespene han reinek\n",
      "lulu la nau tampe luku\n",
      "lulu la luna, moj tähta staastaa otohasa utää foridä semmeTi spöll\n",
      "lulu la našej dzatiš njama ghrulav\n",
      "lulu laoving, laoving la vacée\n",
      "lulu la luhat Lief da borgen\n",
      "lulu la ti p'ra mu alles lumaison\n",
      "lulu la seduce: \"I'll give you one good night to stay and be with me\"\n",
      "lulu la luna täääs liskus senkälka?\n",
      "lulu la luna, italo kolo y mu\n",
      "lulu la ta läsko mogu\n",
      "lulu la, lulu la...\n",
      "lulu la luna luna\n",
      "lulu la luna do apandora\n",
      "lulu laedom klepslien tien, yö hamli eldän öllökö päänkel da\n",
      "lulu la stevia su, iwa tebe os katsu'i pu otras stra alaiShå lumen mir herngol de\n",
      "lulu la tua slalala, leili la banca\n",
      "lulu la vingtala na garlanda – ardidento um beranu\n",
      "lulu laalala lalala lalala...\n",
      "lulu la luce, lele luce\n",
      "lulu la tisti, lulu la tiħa\n",
      "lulu la odra reëveg\n",
      "lulu laft, srå ta'r jeg en vattenfall dig dig får man drælte en liv\n",
      "lulu la nuna kori\n",
      "vobba obdru shtafot zalbim, tvomo inam tevju\n",
      "vobba je sve jećeš da pu vše nam\n",
      "vobba vomo zo słowie słowie\n",
      "vobba roš bolove\n",
      "vobba, det nojed, vnajet zo plaz bilo\n",
      "vobba kad fot und genoegen\n",
      "vobba vodim da jambim\n",
      "vobba je jedam stranjeba\n",
      "vobba i ništa dostu\n",
      "vobba boli i vodka\n",
      "vobba živ prava oči an boljao\n",
      "vobba je plačim tebeč\n",
      "vobba baj trudiš na da me pija\n",
      "vobba, ich macht nach dem Brühen blühen wenn sie dieses Leben mich eine Welt im He\n",
      "vobba, da bašništa s znam\n",
      "vobba kja vjega: otsa ikke jedina\n",
      "vobba mi izdacina\n",
      "vobba je blišto sve\n",
      "vobba jazbudića kome smeta.\n",
      "vobba je živah, svube je suboja\n",
      "vobba i stenga, ich als brennt schmelheut\n",
      "vobba je dobro iz el verlak\n",
      "vobba samo jeg er nu dan\n",
      "vobba bazmila za plav\n",
      "vobba je dig wijs\n",
      "vobba ažan me tvoj z praviča\n",
      "vobba samo vse, dromove ti znam to sve\n",
      "vobba, vobba, nazljal ti za sve\n",
      "vobba i miđlho\n",
      "vobba je najbolj\n",
      "vobba' med mig, skal sve je jag mig skárte\n",
      "vobba cvet, traje dkoj\n",
      "vobba kann ech nicht eine Frauen\n",
      "vobba... gubim shalom\n",
      "vobba davte na smenob\n",
      "vobba mi je, andarim kad selemene\n",
      "vobba menečem kreno, načem mikol utan maar bijem tebmedem\n",
      "vobba je da sve san\n",
      "vobba dnji mi?\n",
      "vobba samo njemto samo\n",
      "vobba bortoviš jasní\n",
      "vobba bašč nash buła, je dzjakuje\n",
      "vobba je vej vrijež na menenbiencijn\n",
      "vobba je skal je budi, znaš neča\n",
      "vobba men nikula\n",
      "vobba i posije\n",
      "vobba mnie wój verdnskaab\n",
      "vobba je oboda\n",
      "vobba je tvoj da život njom još te boj ne više voži\n",
      "vobba daj vej, zal je jeg usa balev\n",
      "vobba mene bilo, da prejednoća da veća\n",
      "vobba balev sammen\n",
      "vobba da stva, nostalgija daj ništi na mia\n",
      "vobba zdajm, da zorž vzori\n",
      "vobba jednom me wYvelias ti apegretud, aydıllar nytyşgünar\n",
      "vobba je stes bridens kennerjeva\n",
      "love was right and everything is right\n",
      "love it all\n",
      "love on-the-fly, joy on-the-fly\n",
      "love to me\n",
      "love, I need your love too\n",
      "love, I don't care what the world may call me\n",
      "love – even though it's sad\n",
      "love in return\n",
      "love can make you feel something\n",
      "love that I have waited\n",
      "love – and that's all that matters\n",
      "love is your kiss for all time\n",
      "love for everyone\n",
      "love, love, love\n",
      "love (still out of love)\n",
      "love is love\n",
      "love is so important\n",
      "love – nothing can tear you apart\n",
      "love is that beautiful thing you say\n",
      "love is dancing with your wildest dreams\n",
      "love is all we need\n",
      "love is through love\n",
      "love's going crazy\n",
      "love is the good old days\n",
      "love can give you all\n",
      "love, your love is a fairy tale\n",
      "love is living in peace\n",
      "love is what makes you believe\n",
      "love is everything I love\n",
      "love can make you believe\n",
      "love was love and love was hate\n",
      "love is like pouring water\n",
      "love my love, you are my everything\n",
      "love me, make me beautiful\n",
      "love can make you sweat, fight all over\n",
      "love is a weapon and we will use it to our fury\n",
      "love I might now\n",
      "love is not me, it's you and me\n",
      "love's beating down the beat\n",
      "love I need to bring you love\n",
      "love's a big thing\n",
      "love is a flame\n",
      "love will come back\n",
      "love, love, love you really love\n",
      "love me, love me forever\n",
      "love, love, love\n",
      "love all your life\n",
      "love is not a thing\n",
      "love we must share\n",
      "love, oh love, I love you.\n",
      "love feels like bliss\n",
      "love is life\n",
      "love is love for you\n",
      "love – be the best, you were always my best\n",
      "love is love, love is love\n",
      "peace and protect the world from all the evil they do\n",
      "peace one, want ta be together\n",
      "peace ör kärlig kannar fast\n",
      "peace you know, then you never know\n",
      "peace alone, everybody knows I am standing strong\n",
      "peace ain't gonna stop\n",
      "peacenellen habibi toest\n",
      "peace we will rise like a phoenix\n",
      "peace would be enough if we all could fight for our right\n",
      "peace and hope are fading\n",
      "peace of love, darling\n",
      "peace against the might and will\n",
      "peace happened when, my friend\n",
      "peace disfrutar og hanmen\n",
      "peace, till we die\n",
      "peace like a flash\n",
      "peace you're sad and lonely\n",
      "peace and compassion\n",
      "peace is yours and you're mine\n",
      "peace I can't go on without you\n",
      "peace brings peace\n",
      "peace of love\n",
      "peace can bring peace\n",
      "peace and see you don't believe, I’m proud to be you truly\n",
      "peace the poor survive the good, yeah\n",
      "peace is fading away, and I keep on wonderin' why\n",
      "peace sejleden meg\n",
      "peace gets used up\n",
      "peace't you stop?\n",
      "peace and prayer, can't hide it\n",
      "peace you’ve got me holding back\n",
      "peace we walked away with tears\n",
      "peace everyone, tell everyone\n",
      "peace, let’s find the love of our lives\n",
      "peace, keep on rolling\n",
      "peace whisper these words to me in my dreams\n",
      "peace of love\n",
      "peace we'll go strong\n",
      "peace games with dice\n",
      "peace's up until sunrise\n",
      "peace knowing that we can stand\n",
      "peace I'm gonna stay and fight\n",
      "peace and life, happiness and pain\n",
      "peace dieses Säivät\n",
      "peace I left?\n",
      "peace the night will fade away\n",
      "peace we will be transformed into shadows\n",
      "peace of love, love\n",
      "peace above me\n",
      "peacear que ader geschérie\n",
      "peace get your freedom now, put your hands up in surrender\n",
      "peace is a story and it has to tell it\n",
      "peace and hope will prevail\n",
      "peace of love\n",
      "peace is bigger\n",
      "peace can decide how it will be\n",
      "peaceful moonlight the land has not seen, nothing yet\n",
      "peace will fall\n",
      "peace can now be won, if you try to hide it\n",
      "power to where I am tonight\n",
      "power and zeal, darkness and hunger\n",
      "power for you and me\n",
      "power is making the sky blue\n",
      "power to whom it’s given\n",
      "power to hold all our rage (Holding all our rage)\n",
      "power percolundian, when you pick a flower\n",
      "powering your million or a million\n",
      "powerces un noche\n",
      "power to avenge,\n",
      "power to all we want\n",
      "power out of the blue\n",
      "power, power of a king\n",
      "power voltage – tell me where to go, tell me where to go\n",
      "power of love\n",
      "powerment, mon cœur qui te bailure\n",
      "power to win over the weak\n",
      "power by a thousand voltrellirs\n",
      "power the tide with love\n",
      "power me up\n",
      "power to carry on\n",
      "power of love, sole source of happiness\n",
      "power of love, would you be there?\n",
      "power to me\n",
      "power of love\n",
      "power to the people we help\n",
      "power of love\n",
      "powerlies at night\n",
      "power we're trembling at the corner of Madrid, (Can't escape)\n",
      "power to keep from harm\n",
      "power my world round and start anew\n",
      "power the world with magic\n",
      "power for life\n",
      "power I'm holding onto\n",
      "power to the untouchable\n",
      "power I'm holding on to\n",
      "power to everybody, everybody\n",
      "powerlessly, it's impossible to change\n",
      "power, I need you\n",
      "power power over Europe\n",
      "power me off this...\n",
      "power with me\n",
      "power and strength are minha to\n",
      "power (Stupid girl)\n",
      "power by a thousand candles\n",
      "power the world with light\n",
      "power of love\n",
      "power to feel that I’m alive\n",
      "power of truth\n",
      "power will make you want to cry\n",
      "power of two stars\n",
      "power and power of the fire\n",
      "power to keep us strong\n",
      "power to those around me\n",
      "power to his fairies\n",
      "power to the people that can take care\n",
      "powerment, couleur parlé de nos réveillentions par rien\n",
      "power to heal us\n",
      "power to the earth\n",
      "power (popular song), love (popular song)\n",
      "power me, just hold me tight\n",
      "power for free.\n",
      "universe lot conveza viva...\n",
      "universe, indie, immer\n",
      "universe (Forget about)\n",
      "universe più solutà\n",
      "universe auf der Nacht\n",
      "universe who you are and what you are not\n",
      "universe, universe, universe\n",
      "universe, um universe\n",
      "universe dat vill das, das nur so bedacht\n",
      "universe – I ain't running anymore\n",
      "universe – broke (Minsterlands 1981)\n",
      "universe nova'ot me'ef staj vektur ba'aim, ah, ah\n",
      "universe part, on ça jamaisse maison à la mer à moi\n",
      "universe and bone to bone\n",
      "universe, planet, our worth is known\n",
      "universe, without repeating itself\n",
      "universe ba täää präamunein kun koshan, sagyaiämun vissoindä saaain\n",
      "universe: freedom will hold on to promise\n",
      "universe aim:Whatever your playboy vibe\n",
      "universe, over your head, tell me why\n",
      "universe (Sing, sing, singe, sang, singe, song)\n",
      "universe, we're all coming together\n",
      "universe leicht nicht sein, denn du bist hauschen in dein\n",
      "universe via trois-veux\n",
      "universe and generality (fly)\n",
      "universe song with a power that goes ding ding-a-dong\n",
      "universe that we could grow\n",
      "universe, the universe\n",
      "universe and beyond the million\n",
      "universe, all the heroes of my dreams\n",
      "universe – In the face of odds\n",
      "universe, we're on the fast track\n",
      "universe, ever since you were three\n",
      "universe fears, its impossible to stop\n",
      "the world is not too big\n",
      "the world around me can tell me lies\n",
      "the world is beautiful\n",
      "the world could be like it was meant to be\n",
      "the world would be right\n",
      "the world was about to begin\n",
      "the world we live in\n",
      "the world knows that I’m proud\n",
      "the world is beautiful and right\n",
      "the world I know\n",
      "the world goes round and round\n",
      "the world goes ding-a-dong, ding-a-dong\n",
      "the world looks peaceful and charming\n",
      "the world was just one\n",
      "the world is ours\n",
      "the world doesn't stop, but it does\n",
      "the world would be a better place\n",
      "the world is a beautiful place\n",
      "the world is bigger\n",
      "the world around you is filled with noise\n",
      "the world lives within our reach\n",
      "the world looks okay\n",
      "the world is repeating itself\n",
      "the world is falling apart\n",
      "the world is a beautiful place\n",
      "the world today is really crazy\n",
      "the world will never be the same, oh yeah\n",
      "the world is yours\n",
      "the world is a beautiful place and you should make it\n",
      "the world is a beautiful place\n",
      "the world is made of stars\n",
      "the world is my creation\n",
      "the world is beautiful\n",
      "the world that weaves\n",
      "the world is just one piece\n",
      "the world is a beautiful place\n",
      "the world is bright\n",
      "the world can be a beautiful place\n",
      "the world has to make a change\n",
      "the world could be crazy\n",
      "the world still gives me wonder\n",
      "the world around you seems to swing in circles\n",
      "the world is yours and we are free\n",
      "the world goes round and round\n",
      "the world is awash\n",
      "the world is not far\n",
      "the world we are, the things you see in your eyes\n",
      "the world is mine\n",
      "the world will be better\n",
      "the world is rough,\n",
      "the world is so right\n",
      "the world can be a mirror, mirror\n",
      "the world has begun\n",
      "the world is really bright\n",
      "the world is our joke\n",
      "the world is beautiful, the world is beautiful\n",
      "the world is in white or black\n",
      "the world is looking good\n",
      "the world that you love\n",
      "the world can be a lovely place\n",
      "the world can be a beautiful place\n",
      "imagination, mas posika mut žakkos\n",
      "imagination and dreams\n",
      "imagination – why can't I see it?\n",
      "imagination, I'd like to see what could come next\n",
      "imagination, I need you more than ever\n",
      "imagination, all you need is imagination\n",
      "imagination – I need your lie\n",
      "imagination, imagination, when you see me smiling\n",
      "imagination, imaginary pas, živim neži mu se živim neži\n",
      "imagination grows inside every living thing\n",
      "imagination given, envy in my mind\n",
      "imagination can guide us\n",
      "imagination, imaginary desire\n",
      "imagination and wonder\n",
      "imagination, adventure, a dream,\n",
      "imagination, where reality is happening\n",
      "imagination told us we couldn't save you\n",
      "imagination, you might be the one\n",
      "imagination, I'm on the verge of hysteria\n",
      "imagination and imagination\n",
      "imagination – that sounds right\n",
      "imagination, yes, it's madness\n",
      "imagination in my dreams\n",
      "imagination and love are signs of where we are\n",
      "imagination, ten thousand tears of the morning air\n",
      "imagination can be a crime\n",
      "imagination – all too soon\n",
      "imagination, a true dream\n",
      "imagination and dreams\n",
      "imagination has already gone\n",
      "imagination – he kinda takes control\n",
      "imagination, (intellectual imagination)\n",
      "imagination without means\n",
      "imagination and prose\n",
      "imagination taking over you\n",
      "imagination in two hearts\n",
      "imagination could be enough to wake me up\n",
      "imagination – premonitions (Denmark 2010)\n",
      "imagination, you said you had no clue\n",
      "imagination and love\n",
      "imagination in the mirror\n",
      "passion has no end, nothing to lose\n",
      "passiono che tu verano che mi no\n",
      "passionène suivre, soit-se suivre des cœurs\n",
      "passion à fleur de l'entre, un joie tout par l'out de moi\n",
      "passion – come on, get movin'\n",
      "passion, love of my life\n",
      "passiono, soulo e verano\n",
      "passionão un refrechtas a meu\n",
      "passion of the skies, love of life\n",
      "passion, que me vindir p'si\n",
      "passion, non qu'on veut-être boum boum boum...\n",
      "passioni per ce \"Médière\"\n",
      "passion, away from dreams and fears\n",
      "passionate me li luda (Luda)\n",
      "passioni di usve, e per sagli, di me reprecechi sarà\n",
      "passion, qui ser connaître doucement\n",
      "passionus – Your Kiss is for everyone\n",
      "passiones d'autresne à la pleine\n",
      "passioni, pensando, pensando\n",
      "passion el annemaMines la vie\n",
      "passion, c'est toi\n",
      "passion rising above\n",
      "passion nama su thima tasi puntoli (Puntoli)\n",
      "passion mourir, senit ça\n",
      "passion céu quero ser pisar\n",
      "passion conmigo, perta via o hinho e tanças\n",
      "passionão ne ftiamentes de tus pies\n",
      "passiona la libertà\n",
      "passion, loin d'ici délà\n",
      "passion à soi, il est là où più arriver\n",
      "passioni di uni\n",
      "passion un y me deuxCui, c'est comme là-bas rien déjà-bas de suaveur?\n",
      "passion mar é finit pour fous\n",
      "passion but pity\n",
      "passione d'Eglion, ne vitro musia\n",
      "passionð vað að siit\n",
      "passionem la bonstería\n",
      "passion hirvärt gehnät\n",
      "passion's taking us down\n",
      "passione prendoi scep\n",
      "passion, gives me courage\n",
      "passion cantar, assim ad an de semmen un coinone\n",
      "passionate jeta nascuno se voglio io foro di un voglio e di io che la vricano veri t\n",
      "passion, I pray to you\n",
      "passion prendano di me\n",
      "passionistio emopresco con se\n",
      "passion au bonheur\n",
      "passion, non sogni\n",
      "passion der deine Milky Way\n",
      "dreams and dreams of young girls\n",
      "dreams, dreams, these are their own monsters\n",
      "dreams show that it's true\n",
      "dreams, fantasies, illusions\n",
      "dreams I never knew\n",
      "dreams still hold me inside\n",
      "dreams are breaking down\n",
      "dreams are not far from reality\n",
      "dreams are opening wide\n",
      "dreams and wonders\n",
      "dreams awake and his words are too hard to say\n",
      "dreams and fantasies, their emptiness is making the sky a happy place\n",
      "dreams of tears and laughs of happiness\n",
      "dreams in our dreams\n",
      "dreams, dreams, all imagination\n",
      "dreams don't fade away\n",
      "dreams shining in your eyes\n",
      "dreams and dreams that could save us\n",
      "dreams always sound good\n",
      "dreams have been lost\n",
      "dreams are dreaming\n",
      "dreams don't lie\n",
      "dreams are cheap, they can lead me crazy\n",
      "dreams and fears\n",
      "dreams are beginning to fall\n",
      "dreams are dancing till sunrise\n",
      "dreams of love, something bigger\n",
      "dreams that seem like they could be over\n",
      "dreams are dreaming, dreams are dreaming\n",
      "dreams still live on the wings of happiness\n",
      "dreams calling the stars\n",
      "dreams always tell the truth\n",
      "dreams are dancing on their dark blue tumblid pillow\n",
      "dreams in the mood\n",
      "dreams, don't lose heart's desire\n",
      "dreams don't matter\n",
      "dreams are blue, dreams are grey\n",
      "dreams just a dream\n",
      "dreams we can hold on to\n",
      "dreams are moving away\n",
      "dreams are calling us\n",
      "dreams are dancing, magic is dancing\n",
      "dreams lost in all their glory\n",
      "dreams always moving, time has come\n",
      "dreams go crazy\n",
      "dreams long gone, our dream is dead\n",
      "dreams are moving away and the noise is getting louder\n",
      "dreams and dreams fly,\n",
      "dreams are moving away from happiness\n",
      "dreams are ringing with emotion\n",
      "dreams can take everything away, but it won't stop there\n",
      "dreams and fantasies, we live in fear\n",
      "dreams, dreams, illusions\n",
      "dreams are turning in the sky\n",
      "dreams of love, of breaking stars\n",
      "dreams so beautiful\n",
      "dreams rise in the sky\n",
      "dreams like a dream\n",
      "dreams never die\n",
      "dreams shining bright like a light\n",
      "dreams are bigger than\n",
      "open, hold my heart\n",
      "open your heart to me\n",
      "open your heart, you're the one I hate\n",
      "open my eyes, open my heart\n",
      "open your heart and hope\n",
      "open up your heart to mine\n",
      "open up your heart, give up on our selfish dreams\n",
      "open the door and I'll make it, alright\n",
      "open a love book and ask me for it\n",
      "open your eyes, this is who I am\n",
      "open the door, no, it won't open the door (door)\n",
      "open me in the memory, taking you in my dreams\n",
      "open me in through my heart\n",
      "open up your heart with love\n",
      "open open wide, how are you?\n",
      "open the door, but no one comes\n",
      "open a heart on the wings of love\n",
      "open in your heart like raindrops\n",
      "open your heart to me\n",
      "open the door\n",
      "open a minute, oh come back to me\n",
      "open your heart, I'm coming alive\n",
      "open eyes, bent hands, bent arms\n",
      "open our eyes and see we are free\n",
      "open your heart, say: Earth is in harmony\n",
      "open to see, no matter what may be between us\n",
      "open a little darkness for me, look at me now\n",
      "open up with love, I ain't scared no more\n",
      "open with whatever you feel in your heart\n",
      "open the distance between us and the stars\n",
      "open up your heart and say it loud\n",
      "open a cigarette, take a look around\n",
      "open up your heart\n",
      "open a little door that's ajar\n",
      "open up your heart, come on with me and live my life like a butterfly\n",
      "open a bag with your lover\n",
      "open and close your eyes – it seems the world is beginning\n",
      "open up your heart, show your emotions\n",
      "open up your heart, keep it in my hands\n",
      "openen playboy, et bleu playboy\n",
      "open your eyes, you came with me\n",
      "open the doorbell\n",
      "open your heart to love\n",
      "open up your heart, unite your colours\n",
      "open up your heart for love\n",
      "open a door, open the door\n",
      "open the door\n",
      "open my heart to you\n",
      "open up your heart\n",
      "open your heart, keep running free\n",
      "open the door\n",
      "open your eyes\n",
      "open your eyes, I’ll be with you\n",
      "open a world with you\n",
      "open out of the blue\n",
      "open up your heart to love\n",
      "open your heart\n",
      "open doors, but we won't give in\n",
      "open the door, welcome the guest (Fly, babe)\n",
      "open up the heart – I ain't scared no more\n",
      "open the hope, you will find me\n",
      "open the door\n",
      "open up your heart for me, my love\n",
      "flying a flag for you and I\n",
      "flying away, you are free\n",
      "flying in the stream\n",
      "flying the flag for peace\n",
      "flying legs, feet, glistening, black wings\n",
      "flying away so mad, off the face of reality\n",
      "flying the flag for you\n",
      "flying over the bridge of the sun\n",
      "flying all day long\n",
      "flying the flag to fly\n",
      "flying like a trumpet\n",
      "flying on the wings of love\n",
      "flying away from home\n",
      "flying away like my heroes did\n",
      "flying in love at once\n",
      "flying back to earth\n",
      "flying wings of love\n",
      "flying with blue wings\n",
      "flying away from my reality\n",
      "flying down, all the time flying up\n",
      "flying back in the blue\n",
      "flying me high and fly\n",
      "flying with the lions\n",
      "flying down the stairs\n",
      "flying and be flying high\n",
      "flying in my soul\n",
      "flying away from your eyes\n",
      "flying away but look within me\n",
      "flying into love\n",
      "flying on the wings of love\n",
      "flying flying high\n",
      "flying to the stars, I wanna fly high\n",
      "flying wings of love\n",
      "flying, I fly to your heaven\n",
      "flying up in the sky like a cannonball\n",
      "flying from this world that has gone apart\n",
      "flying la la la la la la la la... dak da znam da da jastan (Kom)\n",
      "flying out of my mind\n",
      "flying away, fly away, fly away\n",
      "flying to the stars\n",
      "flying into action\n",
      "flying away in the moonlight\n",
      "flying away in fear\n",
      "flying in fear but love keeps on coming\n",
      "flying as one\n",
      "flying away and get it all back?\n",
      "flying flyin' high\n",
      "flying away from here\n",
      "flying, flying, flying, flying\n",
      "flying the flag for love\n",
      "flying through the black\n",
      "flying out of the blue\n",
      "flying though the wind is blowing\n",
      "flying legs, fly wings, fly higher\n",
      "flying back and facing the danger\n",
      "flying, flying, flying\n",
      "flying wings of love\n",
      "flying with the stars of love\n",
      "welcome to the party\n",
      "welcome me, I won't care\n",
      "welcome, I've been waiting for this night\n",
      "welcome home, hey hey\n",
      "welcome back, welcome back\n",
      "welcome, welcome to join me\n",
      "welcome to our home\n",
      "welcome will you be my everything?\n",
      "welcome arms, everyone welcome\n",
      "welcome to bring you up\n",
      "welcome to our funky old world\n",
      "welcome to a new era\n",
      "welcome dajde in uveće da\n",
      "welcome u non ti meurti\n",
      "welcome to thank you\n",
      "welcome home, oh welcome home, oh oh oh...\n",
      "welcome for you\n",
      "welcome to your side\n",
      "welcome, welcome, it's done\n",
      "welcome and welcome and welcome and welcome and\n",
      "welcome to be the same, just you and I\n",
      "welcome, you're welcome\n",
      "welcome to the start\n",
      "welcome ich so immer nicht weh\n",
      "welcome to enjoy the new millennium\n",
      "welcome home of home of home of home\n",
      "welcome dolly, welcome dolly\n",
      "welcome to unite us again\n",
      "welcome to welcome you back\n",
      "welcome to your home\n",
      "welcome to care\n",
      "welcome to Amsterdam\n",
      "welcome to a time when love was cheap,\n",
      "welcome à barco toujours d'amour\n",
      "welcome to meet and see\n",
      "welcome, welcome, welcome\n",
      "welcome to an evil world\n",
      "welcome to the new world\n",
      "welcome bringer hat es frei\n",
      "welcome I can be everywhere\n",
      "welcome we come\n",
      "welcome a world in which we're allowed\n",
      "welcome nightwomen gjuszâll, engehmerz oschennt.\n",
      "welcome, we welcome\n",
      "welcome to the café\n",
      "welcome to his world\n",
      "welcome to this show\n",
      "welcome, welcome home\n",
      "welcome this new world\n",
      "welcome to a love I've never known\n",
      "welcome to be here\n",
      "lagom stär vi bara kad mig öppet hörstår en dogstick i götesklenmen sk\n",
      "lagom av täälme erande elähtin vei\n",
      "lagom ett ett står og aldrig af\n",
      "lagom nekig een breit vogels, min vällt sehn\n",
      "lagom mot nat, kunnenslalorni vethett spärlighed\n",
      "lagom östiglenar igen kun er första zijn en lämmer\n",
      "lagom i stviliši, znam ime\n",
      "lagom övig, hör sig ingen hör inte du förstår stanmer\n",
      "lagom et ha läsigkeit\n",
      "lagom vällt mig mig natten voll\n",
      "lagom mig, davalle dig\n",
      "lagom den eller vår er tight har ab din stårlig drømmer sti finnsinken ätt en fas\n",
      "lagomu – huis im MacauanIn kopen hoon denhmämpaa, sous huis laannäm\n",
      "lagom ingen ksímos ja efkull vi besviener\n",
      "lagom mig an min erklän zorgen er står\n",
      "lagom vex og no din þer skibet\n",
      "lagom v har mot, bringlek mag ønsker.\n",
      "lagom om ett\n",
      "lagom så slor\n",
      "lagom estegott mehr ungehntetig en frage\n",
      "lagom håst blidor fra ser vil som det i mintern\n",
      "lagom föhltson som mit sina, ystäln på lang?\n",
      "lagomim tashkin yilmashvavim\n",
      "lagomine sind läkkeinem, kan päivärle fle'r used mejesvält\n",
      "lagom, har kadmeit elag\n",
      "lagom, det ett länder\n",
      "lagom ger vi tva'ata\n",
      "lagom hörtet ich mit nicht, dazchhört mehr als, wie heiß wir ein\n",
      "lagomot hojneme bara gå?\n",
      "lagom din taşkımı müşlarlarun\n",
      "lagom i'll til stupa\n",
      "lagom sa'ar sta hernez takinen\n",
      "lagomim mylma mujnom samo\n",
      "lagom glück'n, ett mani nom overpecken\n",
      "lagom bin ich mit spøllen\n",
      "lagom öppen hässö\n",
      "lagom et når jeg solen på atld som slår vill\n",
      "lagom vi agapi til 'bi, i sve altrai, yuvuzi et ha'aminmi szetta hodi\n",
      "lagom en så lått altbrävt gar det, slår vi det blid mig vi garjär\n",
      "lagomne dakteri staastavai stoissimi\n",
      "lagom, stoltade lärt som står vänen\n",
      "lagom anjö lite sakatten lässa\n",
      "lagom føler och vår\n",
      "lagom ds-je čarme su villim\n",
      "lagomav igen na ditt\n",
      "lagom sår kommens er med meg til hånden er bare\n",
      "lagom mig till i dig i på vem af meg\n",
      "lagom mig så man är ett\n",
      "lagom bom v menet nog razom\n",
      "lagom är nog gammen, og är godt måndet den dep: ärligheder \n",
      "lagom med dröm\n",
      "lagom i nat\n",
      "lagom stadt förstälskeldt\n",
      "lagom ör görmen ändens dägt nog og kleine grittner mig lang kopps fö\n",
      "lagom ples indiano\n",
      "lagom što sve\n",
      "lagom en er lommis så liv\n",
      "mysa – I think it's magic\n",
      "mysa hukar vänd, og mørme\n",
      "mysa augustun um causeвmir sur igli tym\n",
      "mysa noći mi dva\n",
      "mysa tu maiseris\n",
      "mysaio ne apse\n",
      "mysa di mani\n",
      "mysa i snazka, i muşpene joşi\n",
      "mysa lalla lita da aixi\n",
      "mysa mi chica senza\n",
      "mysa sarhora no takazi?\n",
      "mysa goz'öretem \"Más rezedalasa\"\n",
      "mysa mira la luna\n",
      "mysa with svoj da stolkede\n",
      "mysa rejina ajdeš\n",
      "mysa kutsu tu matuus, nanana lutsu\n",
      "mysa od chesnati\n",
      "mysa da samo oči\n",
      "mysa se 'cause when a man lies, his body is bare\n",
      "mysa sole, l'argent ouvre la luna\n",
      "mysa maliti et aligit\n",
      "mysa noću sentido,\n",
      "mysa: san, an ti\n",
      "mysa che te hinen ka fini voixume keiseinuizihia\n",
      "mysa má-tá onde pá-de blir na vár-de grin\n",
      "mysa matina – hama apia (Georgia)\n",
      "mysa for a miracle, ajan veljem\n",
      "mysa zvezda, baila baila zvezda\n",
      "mysa mas izм\n",
      "mysa stas maktyu as:\n",
      "mysa lacrima a slvi\n",
      "mysa sei svige tão med rio\n",
      "mysa los bijos, perdido cantar\n",
      "mysa matos perdón\n",
      "mysa mi inita\n",
      "mysa comis soás\n",
      "mysa tinopodi nechka bylai za chga za in i slukule, ki tinoho mi innu bir, t\n",
      "mysa da sei, na sve samo\n",
      "mysa usko da luna\n",
      "mysa há sempre sauma\n",
      "mysa salmi mira\n",
      "mysa, nasja lični\n",
      "mysa nahta xanaut\n",
      "mysa punia e poi\n",
      "mysa noite d'že na mojažnđ\n",
      "mysa kanan apne olsz ljubav\n",
      "mysa sve ráš – koš po dzjáš\n",
      "mysa élha, na moros mismeni\n",
      "mysa mais teupal\n",
      "mysa me i všo vita\n",
      "mysa coziesza meisje en mar\n",
      "mysa san tym – seris\n",
      "mysa ke kol moja\n",
      "mysa la soy inne à luz\n",
      "mysa y mi foglio, te perduna\n",
      "mysa la ti fa she ti\n",
      "oh ah la la... la... la... la la la la... la la la la la la la la la la la... la la la la la la l\n",
      "oh ah la la la la la la la la...\n",
      "oh ah la... luna luna luna la...\n",
      "oh ah la... hah la...\n",
      "oh ah la la la la la...\n",
      "oh ah la la la la la la la la la la... la la la la la la la...\n",
      "oh ah la la la la...\n",
      "oh ah la la... la la la la la la la la...\n",
      "oh ah la la la la la...\n",
      "oh ah la la... la la... la lala lalala lala lala lala la lala...\n",
      "oh ah la, ¿quién maneja mi barca?\n",
      "oh ah la lalala lalala...\n",
      "oh ah la... (Oh ah la...)\n",
      "oh ah la... la la...\n",
      "oh ah la, oh ah la la, la la, la la la la la la la la la la la la la la... la la la la la l\n",
      "oh ah la... (Oh ah la... oh la...)\n",
      "oh ah la la la…\n",
      "oh ah la la... la... la...\n",
      "oh ah la la... oh ah la la...\n",
      "oh ah la la la la la la......\n",
      "oh ah la, ah la\n",
      "Löpsedel al löyde forlön om det wat af dag\n",
      "Löpsedel, jag, cojedema: slår for värme\n",
      "Löpsedel mehr unserdomen hörstlich ihn bistig Sonnenschein dir daran lausie von dach\n",
      "Löpsedel mædal til mig\n",
      "Löpsedel ich ancora?\n",
      "Löpsedel v på at må føldör\n",
      "Löpsedel man, nepp i snörragen\n",
      "Löpsedelle en mar\n",
      "Löpsedel som på ensom må\n",
      "Löpsedel, leymeda, leymeda\n",
      "Löpsedelene förstår nat svær påvind: godot je va'me blå tær kor:\n",
      "Löpsedeln een så lengen aan\n",
      "Löpsedel loet van dag\n",
      "Löpsedelis – velikulkeia i musastaa\n",
      "Löpsedelkama när tekka avälva sólov\n",
      "Löpsedel så når naden och vänglighetne med vi hjertet\n",
      "Löpsedeler tähtällaan apien päivä on tähtällen apien ihtällen apien \n",
      "Löpsedel elke på på må då du værr til\n",
      "Löpsedel só láur,\n",
      "Löpsedelen må på kitt tuslepeten\n",
      "Löpsedelen kleinen wagen görst kleines lås barco und das langsens baroit\n",
      "Löpsedel at mir in de chrennen ein Dichstehn\n",
      "Löpsedel du... nihta er'lägt, nur ein'lägt, sägt dir einen dir vä\n",
      "Löpsedel me'ülsicht nur euch\n",
      "Löpsedelungen mot viellech vind ik nur spelzen\n",
      "Löpsedelen szommen kronszargielen\n",
      "Löpsedel i hengel mig\n",
      "Löpsedelou vaheen umeen aankiisiisen\n",
      "Löpsedelen naar komennen\n",
      "Löpsedelen öppölker öppät – Eller Kvällen därlekten öpp\n",
      "Löpsedel jag skærlig år melner\n",
      "Löpsedel over Känge tännecken\n",
      "Löpsedelte naar datkatt du mir voeel jouingen\n",
      "Löpsedel ja med endn þari\n",
      "Löpsedel to hæga biak\n",
      "Löpsedel zijn je darten gaan\n",
      "Löpsedel gözetken geck träumen, damen så'n stond förstång du langt nås\n",
      "Löpsedel når du var små luixika\n",
      "Löpsedel er visa\n",
      "Löpsedel du zo nu dig\n",
      "Löpsedel träumen aus Läumen\n",
      "Löpsedelig meis, efð efð að efð tilforn sonka tullen álleur all\n",
      "Löpsedelen prizne so vämmer coppst de servelen i väselke mig\n",
      "Löpsedeler og i en vår\n",
      "Löpsedelen zwei für dich jedenden takjeszio zo zonder bailegen\n",
      "Löpsedel vam, meleë gird, mylen ullen solen aanjë luocille muisiat p\n",
      "Löpsedelen lyschiere av elkam\n",
      "Löpsedel vedamo täälku med i voisi, löpsedel käntå dig vända vi h\n",
      "Löpsedel et s'evendskonder meg öllust du öellust sägen immer helselet\n",
      "Löpsedelörn les griots jeden?\n",
      "Löpsedelos não de far\n",
      "Löpsedel jeg die mir loi\n",
      "Löpsedeljen kærmellen förstatten\n",
      "Löpsedelen og grøler har ingen'r fram kærlighedelen kærlighedecket?\n",
      "Löpsedel med meg, så mansemen en kunnen dig\n",
      "Löpsedel yvetsin mig sonlen vill vespekt, elleller mig sig, les bestarr ügeven\n",
      "Löpsedelen hört kan lösten blöder Süenburger Torsten korten sig förstår er diese\n",
      "Ratatatie, neranu muşchad apoi\n",
      "Ratatatim la mis otakh\n",
      "Ratatat to non per pudesve lume\n",
      "Ratatat se kathrakkina su ti zrathrak\n",
      "Ratatat je lille maan hayat\n",
      "Ratatat baulım shalit as sin\n",
      "Ratatat hayim, hachalat ta'amin\n",
      "Ratatat pexat haya voz\n",
      "Ratatatim yurim shel niinulot\n",
      "Ratatat laimında shehaylar\n",
      "Ratatat (btat) oči mušto tašto da vratiš\n",
      "Ratatat bana plika\n",
      "Ratatat maunbi, bez dat makda?\n",
      "Ratatat me moje v jag mån\n",
      "Ratatat godala,ku yaştye adam moçteb\n",
      "Ratatat elkothe enfav\n",
      "Ratatatih uuso niinorech sech ha'ar osty othesiv\n",
      "Ratatat se kahtat\n",
      "Ratatat sunni haba da da hachmachiyo\n",
      "Ratatat ha'el'ar, yad le'alshe'ar elchan\n",
      "Ratatatama me lama bez trujata lamaan?\n",
      "Ratatatim hu'amar mu ba'el'el luvot\n",
      "Ratatat bol Musul\n",
      "Ratatat meba, ner dan laskhar\n",
      "Ratatat yoi otostop\n",
      "Ratatat tha tha kemon ti\n",
      "Ratatat maaaa na (Opa…) khi se kaata (Pkaata)\n",
      "Ratatat mes arkach; ha'alayesh, mevran ha'aim hachaim hachaim hachaimash\n",
      "Ratatat, we får vi tå så bår vi vad\n",
      "Ratatat je sana moe tusitarävle\n",
      "Ratatata shekar hayatir\n",
      "Ratatat bilo ne plelukat ek\n",
      "Ratatat din kansi yot\n",
      "Ratatateto, tiempo, tiempo istte hoogevaan veiaksa mu raspälleiset\n",
      "Ratatat je meis og bæus-rat je jeg visit toit, vereta gårver, hosk'\n",
      "Ratatat zaretsa srceto\n",
      "Ratatat el ba'em\n",
      "Ratatat al yedi'ser,\n",
      "Ratatat i din site\n",
      "Ratatat vilati, samino karem\n",
      "Ratatat for sag' si semvetsin karfum shelkulat sa' taina karfare\n",
      "Ratatat, kene vi soli e os kardhiaia känna?\n",
      "Ratatatze, žim kemma nazrat\n",
      "Ratatatina da symmatola\n",
      "Ratatat odbi serti\n",
      "Ratatat (Tomat), dudajte v me mi sam to žiram\n",
      "Ratatatma, verhatram mu'am\n",
      "Ratatat porgi tare\n",
      "Ratatat hadka tobame ta'at bachal kol yaf\n",
      "Ratatat mi sikaanabat\n",
      "Ratatat'i v le'ani teshem ani\n",
      "Ratatat muzarmat ee Has Two hearts\n"
     ]
    }
   ],
   "source": [
    "''' perform batch text generation '''\n",
    "\n",
    "#seeds = ['love', 'peace', 'power', 'flight', 'universe', 'the world', 'imagination', 'passion', 'dreams', 'open']\n",
    "\n",
    "seeds = ['ding a dong', 'lulu la', 'vobba', 'love', 'peace', 'power', 'universe', 'the world',\n",
    "         'imagination', 'passion', 'dreams', 'open', 'flying', 'welcome', 'lagom', 'mysa', 'oh ah la', 'Löpsedel', 'Ratatat']\n",
    "\n",
    "store = []\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    # input prompt to model\n",
    "    #prompt: str = 'magic.'\n",
    "    #prompt: str = '{}!'.format(seed)\n",
    "    prompt: str = '{}'.format(seed)\n",
    "\n",
    "    # max length desired output\n",
    "    length: int = 30\n",
    "\n",
    "    # Token at which text generation is stopped\n",
    "    #stop_token: str = None\n",
    "    stop_token: str = '!'\n",
    "\n",
    "\n",
    "    # temperature of 1.0 has no effect, lower tend toward greedy sampling\n",
    "    temperature:float = 1.\n",
    "\n",
    "\n",
    "    # primarily useful for CTRL model; in that case, use 1.2\n",
    "    repetition_penalty: float = 1.\n",
    "\n",
    "\n",
    "    k: int = 0\n",
    "    p: float = 0.9\n",
    "\n",
    "\n",
    "    # The number of samples to generate\n",
    "    num_return_sequences: int = 64\n",
    "\n",
    "\n",
    "    # Initialize the model and tokenizer\n",
    "    #model_class, tokenizer_class = (GPT2LMHeadModel, GPT2Tokenizer)\n",
    "\n",
    "    #tokenizer = tokenizer_class.from_pretrained('gpt2')\n",
    "    #model = model_class.from_pretrained('../data/lyrics/model-en-lyrics-02')\n",
    "    #model.to(device)\n",
    "\n",
    "\n",
    "    MAX_LENGTH = int(10000)  # Hardcoded max length to avoid infinite loop\n",
    "\n",
    "    def adjust_length_to_model(length, max_sequence_length):\n",
    "        if length < 0 and max_sequence_length > 0:\n",
    "            length = max_sequence_length\n",
    "        elif 0 < max_sequence_length < length:\n",
    "            length = max_sequence_length  # No generation bigger than model size\n",
    "        elif length < 0:\n",
    "            length = MAX_LENGTH  # avoid infinite loop\n",
    "        return length\n",
    "\n",
    "    length = adjust_length_to_model(\n",
    "        length, max_sequence_length = model.config.max_position_embeddings)\n",
    "\n",
    "\n",
    "    # encode prompt text, push to device\n",
    "    prompt_text = prompt\n",
    "    encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens = False, return_tensors = \"pt\")\n",
    "    encoded_prompt = encoded_prompt.to(device)\n",
    "\n",
    "\n",
    "    # generate output sequence\n",
    "    output_sequences = model.generate(\n",
    "\n",
    "        input_ids = encoded_prompt,\n",
    "\n",
    "        max_length = length + len(encoded_prompt[0]),\n",
    "        temperature = temperature,\n",
    "        top_k = k,\n",
    "        top_p = p,\n",
    "        repetition_penalty = repetition_penalty,\n",
    "        do_sample = True,\n",
    "        num_return_sequences = num_return_sequences,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Remove the batch dimension when returning multiple sequences\n",
    "    if len(output_sequences.shape) > 2:\n",
    "        output_sequences.squeeze_()\n",
    "\n",
    "    generated_sequences = []\n",
    "\n",
    "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "\n",
    "        generated_sequence = generated_sequence.tolist()\n",
    "\n",
    "        # Decode text\n",
    "        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces = True)\n",
    "\n",
    "        # Remove all text after the stop token\n",
    "        text = text[: text.find(stop_token) if stop_token else None]\n",
    "\n",
    "        # Add the prompt at the beginning of the sequence.\n",
    "        # Remove the excess text that was used for pre-processing\n",
    "        total_sequence = (\n",
    "            prompt_text + text[len(tokenizer.decode(\n",
    "                encoded_prompt[0], clean_up_tokenization_spaces = True)) :] )\n",
    "\n",
    "        #generated_sequences.append(total_sequence[len(prompt):])\n",
    "        #print(total_sequence)\n",
    "        \n",
    "        if len(total_sequence[len(prompt_text):].split(' ')) > 2:\n",
    "            generated_sequences.append(total_sequence)\n",
    "            #print(total_sequence)\n",
    "\n",
    "    #return generated_sequences\n",
    "    \n",
    "    store.append(generated_sequences)\n",
    "    \n",
    "    for line in generated_sequences:\n",
    "        #store.append(line)\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' save batch text '''\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "\n",
    "    with open('../data/lyrics/output/v2/lyrics-{}.txt'.format(seeds[i]), 'w', encoding='utf-8') as file:\n",
    "        file.writelines('\\n'.join(store[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eurovision-ai",
   "language": "python",
   "name": "eurovision-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
